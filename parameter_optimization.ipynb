{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(fname: str):\n",
    "    return Word2Vec.load(fname)\n",
    "\n",
    "def compute_sentence_embedding(sentence, model, a):\n",
    "    \"\"\"\n",
    "    如果词向量不存在应该如何处理？（目前的处理是忽略该词向量）(out-of-word)\n",
    "    \"\"\"\n",
    "    words = cut_words(sentence)\n",
    "    # 词向量加权求和\n",
    "    word_embeddings = np.array([a / (a + (model.wv.vocab[word].count / model.corpus_total_words)) * model.wv[word] for word in words if word in model.wv])\n",
    "    return np.sum(word_embeddings, axis=0) / word_embeddings.shape[0]\n",
    "\n",
    "def cut_words(content: str):\n",
    "    return [word for word in list(jieba.cut(clean_data(content))) if word != ' ']\n",
    "\n",
    "def clean_data(content: str):\n",
    "    chinese_punctuation = '＂＃＄％＆＇（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､\\u3000、〃〈〉《》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏﹑﹔·！？｡。'\n",
    "    english_punctuation = ',.?;:\\'\"`~!'\n",
    "    special_char = r'<>/\\\\|\\[\\]{}@#\\$%\\^&\\*\\(\\)-\\+=_\\n'\n",
    "    return re.sub('(?P<punctuation>[{}]|[{}])|(?P<special_char>[{}])'.format(chinese_punctuation, english_punctuation, special_char), ' ', content)\n",
    "\n",
    "def cos_dist(vec1,vec2):\n",
    "    \"\"\"\n",
    "    :param vec1: 向量1\n",
    "    :param vec2: 向量2\n",
    "    :return: 返回两个向量的余弦相似度\n",
    "    \"\"\"\n",
    "    dist1=float(np.dot(vec1,vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2)))\n",
    "    return dist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/mengzeyu/Downloads/word2vec_normal_full.model'\n",
    "model = load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open('/Users/mengzeyu/Downloads/simtrain_to05sts.txt', 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_A =[]\n",
    "sentences_B=[]\n",
    "scores = []\n",
    "for line in lines:\n",
    "    parts = line.split('\\t')\n",
    "    sentences_A.append(parts[1])\n",
    "    sentences_B.append(parts[3])\n",
    "    score = float(parts[4].replace('\\n',''))/5.0\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/k2/t_qs4tk92z73ct1c5lyhs_bm0000gq/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.760 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8405600351675138\n",
      "0.0002\n",
      "0.8244173574311611\n",
      "0.00030000000000000003\n",
      "0.8133818943603435\n",
      "0.0004\n",
      "0.8050785496203428\n",
      "0.0005\n",
      "0.798484895654453\n",
      "0.0006000000000000001\n",
      "0.7930559810505952\n",
      "0.0007000000000000001\n",
      "0.7884673029443493\n",
      "0.0008\n",
      "0.784510494249119\n",
      "0.0009000000000000001\n",
      "0.7810441495318403\n",
      "0.001\n",
      "0.7779681752448138\n"
     ]
    }
   ],
   "source": [
    "for a in np.arange(1e-4, 1.1e-3, 1e-4):\n",
    "    truth =[]\n",
    "    predicts = []\n",
    "    print(a)\n",
    "    for i in range(len(sentences_A)):\n",
    "        sentence_a=compute_sentence_embedding(sentences_A[i], model, a)\n",
    "        sentence_b=compute_sentence_embedding(sentences_B[i], model, a)\n",
    "        if isinstance(sentence_a,np.ndarray) and isinstance(sentence_b,np.ndarray):\n",
    "            truth.append(scores[i])\n",
    "            predict = cos_dist(sentence_a,sentence_b)\n",
    "            predicts.append(predict)\n",
    "    print(pearsonr(truth, predicts)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
